<!doctype html>
<html amp lang="en">
<head>
    <meta charset="utf-8">
    <title>Performance Tuning Queries in PostgreSQL</title>
    <link rel="canonical" href="https://www.geekytidbits.com/performance-tuning-postgres/" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Poly' rel='stylesheet'>
    <style amp-custom>
        body { font-family: 'Poly', serif; }
        .site-header { background-color: #237ab2; color: #e7e9ec; padding: 5px; font-weight: 100; border-bottom: 3px solid #f68905; }
        .site-description { font-size: .5em;}        
        .post-content { padding: 10px; }
    </style>
    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async custom-element="amp-analytics" src="https://cdn.ampproject.org/v0/amp-analytics-0.1.js"></script>
    <script async custom-element="amp-iframe" src="https://cdn.ampproject.org/v0/amp-iframe-0.1.js"></script>
    <script async custom-element="amp-video" src="https://cdn.ampproject.org/v0/amp-video-0.1.js"></script>
    <script async custom-element="amp-youtube" src="https://cdn.ampproject.org/v0/amp-youtube-0.1.js"></script>
    <script async src="https://cdn.ampproject.org/v0.js"></script>
</head>

<body>
    
    <h1 class="post-title">
        <header class="site-header">
    <div class="wrapper">
        <a class="site-title" href="/">
            <amp-img src="/media/geekytidbits.png" width="383" height="46" alt="Geeky Tidbits Logo" layout="responsive"><noscript><img src="/media/geekytidbits.png" width="383" height="46" alt="Geeky Tidbits Logo"></noscript></amp-img>
        </a>
        <div class="site-description">Tidbits on software development, technology, and other geeky stuff.</div>
    </div>
</header>

    </h1>
    <div class="post-content">
      <span>
          <i>Jan 20, 2016</i>
      </span>
      <p>Database performance tuning: developers usually either love it or loathe. I happen to be one that enjoys it and want to share some of the techniques I’ve been using lately to tune poor performing queries in PostgreSQL. This is not meant to be exhausive but more of a primer for those just getting their feet wet with tuning.</p>

<h2 id="finding-slow-queries">Finding Slow Queries</h2>

<p>One obvious way to start with tuning is to find specific statements that are performing poorly.</p>

<h3 id="pg_stats_statements">pg_stats_statements</h3>

<p>The <a href="http://www.postgresql.org/docs/current/static/pgstatstatements.html">pg_stats_statements</a> module is a great place to start. It simply tracks execution statistics of SQL statements and can be an easy way to find poor performing queries.</p>

<p>Once you have this module installed, a system view named <code class="highlighter-rouge">pg_stat_statements</code> will be available with all sorts of goodness. Once it has had a chance to collect a good amount of data, look for
queries that have relatively high <code class="highlighter-rouge">total_time</code> value. Focus on these statements first.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span>
  <span class="n">pg_stat_statements</span>
<span class="k">ORDER</span> <span class="k">BY</span>
  <span class="n">total_time</span> <span class="k">DESC</span><span class="p">;</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>user_id</th>
      <th>dbid</th>
      <th>queryid</th>
      <th>query</th>
      <th>calls</th>
      <th>total_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>16384</td>
      <td>16385</td>
      <td>2948</td>
      <td>SELECT address_1 FROM addresses a INNER JOIN people p ON a.person_id = p.id WHERE a.state = @state_abbrev;</td>
      <td>39483</td>
      <td>15224.670</td>
    </tr>
    <tr>
      <td>16384</td>
      <td>16385</td>
      <td>924</td>
      <td>SELECT person_id FROM people WHERE name = @name;</td>
      <td>26483</td>
      <td>12225.670</td>
    </tr>
    <tr>
      <td>16384</td>
      <td>16385</td>
      <td>395</td>
      <td>SELECT _ FROM orders WHERE EXISTS (select _ from products where is_featured = true)</td>
      <td>18583</td>
      <td>224.67</td>
    </tr>
  </tbody>
</table>

<h3 id="auto_explain">auto_explain</h3>

<p>The <a href="http://www.postgresql.org/docs/current/static/auto-explain.html">auto_explain</a> module is also helpful for finding slow queries but has 2 distinct advantages: it logs the actual execution plan and supports logging <em>nested statements</em> using the <code class="highlighter-rouge">log_nested_statements</code> option. Nested statements are those statements that are executed inside a function. If your application uses many functions, auto_explain is invaluable for getting detailed execution plans.</p>

<p>The <code class="highlighter-rouge">log_min_duration</code> option controls which query execution plans are logged, based on how long they perform. For example, if you set this to 1000, all statments that run longer than 1 second will be logged.</p>

<h2 id="index-tuning">Index Tuning</h2>

<p>Another important tuning strategy is to ensure indexes are being properly used. As a prerequsite, we need to turn on the Statistics Collector.</p>

<p>The <a href="http://www.postgresql.org/docs/current/static/monitoring-stats.html">Postgres Statistics Collector</a> is a first class subsystem that collects all sorts of performance statistics that are useful.</p>

<p>Turning this collector on gives you tons of <code class="highlighter-rouge">pg_stat_...</code> views which contain all the goodness. In particular, I have found it to be particularly useful for finding missing and unused indexes.</p>

<h3 id="missing-indexes">Missing Indexes</h3>

<p>Missing indexes can be one of the easiest solutions to increasing query performance. However, they are not a silver bullet and should be used properly (more on that later). If you have The Statistics Collector turned on, you can run the following query (<a href="http://stackoverflow.com/a/12818168/626911">source</a>).</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>
  <span class="n">relname</span><span class="p">,</span>
  <span class="n">seq_scan</span> <span class="o">-</span> <span class="n">idx_scan</span> <span class="k">AS</span> <span class="n">too_much_seq</span><span class="p">,</span>
  <span class="k">CASE</span>
    <span class="k">WHEN</span>
      <span class="n">seq_scan</span> <span class="o">-</span> <span class="n">coalesce</span><span class="p">(</span><span class="n">idx_scan</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">THEN</span>
      <span class="s1">'Missing Index?'</span>
    <span class="k">ELSE</span>
      <span class="s1">'OK'</span>
  <span class="k">END</span><span class="p">,</span>
  <span class="n">pg_relation_size</span><span class="p">(</span><span class="n">relname</span><span class="p">::</span><span class="n">regclass</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rel_size</span><span class="p">,</span> <span class="n">seq_scan</span><span class="p">,</span> <span class="n">idx_scan</span>
<span class="k">FROM</span>
  <span class="n">pg_stat_all_tables</span>
<span class="k">WHERE</span>
  <span class="n">schemaname</span> <span class="o">=</span> <span class="s1">'public'</span>
  <span class="k">AND</span> <span class="n">pg_relation_size</span><span class="p">(</span><span class="n">relname</span><span class="p">::</span><span class="n">regclass</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">80000</span>
<span class="k">ORDER</span> <span class="k">BY</span>
  <span class="n">too_much_seq</span> <span class="k">DESC</span><span class="p">;</span>
</code></pre></div></div>

<p>This finds tables that have had more Sequential Scans than Index Scans, a telltale sign that an index will usually help. This isn’t going to tell you which columns to create the index on so that will require a bit more work. However, knowing which table(s) need them is a good first step.</p>

<h3 id="unused-indexes">Unused Indexes</h3>

<p>Index all the things right? Did you know having unused indexes can negatively affect write performance? The reason is, when you create an index, Postgres is burdened with the task of keeping this index updated after write (INSERT / UPDATE / DELETE) operations. So, adding an index is a balancing act because they <em>can</em> speed up reading of data (if created properly) but <em>will</em> slow down write operations. To find unused indexes you can run the following command.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>
  <span class="n">indexrelid</span><span class="p">::</span><span class="n">regclass</span> <span class="k">as</span> <span class="k">index</span><span class="p">,</span>
  <span class="n">relid</span><span class="p">::</span><span class="n">regclass</span> <span class="k">as</span> <span class="k">table</span><span class="p">,</span>
  <span class="s1">'DROP INDEX '</span> <span class="o">||</span> <span class="n">indexrelid</span><span class="p">::</span><span class="n">regclass</span> <span class="o">||</span> <span class="s1">';'</span> <span class="k">as</span> <span class="n">drop_statement</span>
<span class="k">FROM</span>
  <span class="n">pg_stat_user_indexes</span>
  <span class="k">JOIN</span>
    <span class="n">pg_index</span> <span class="k">USING</span> <span class="p">(</span><span class="n">indexrelid</span><span class="p">)</span>
<span class="k">WHERE</span>
  <span class="n">idx_scan</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">AND</span> <span class="n">indisunique</span> <span class="k">is</span> <span class="k">false</span><span class="p">;</span>
</code></pre></div></div>

<h3 id="a-note-about-statistics-on-development-environments">A note about statistics on development environments</h3>

<p>Relying upon statistics generated from a local development database can be problematic. Ideally you are able to pull the above statistics from your production machine or generate them from a restored production backup. Why? Environmental factors can and do change the way Postgres query optimizer works. Two examples:</p>

<ul>
  <li>when a machine has less memory PostgreSQL may not be able to perform a Hash Join when otherwise it would be able to and would make the join faster.</li>
  <li>if there are not many rows in a table (like in a development database), PostgresSQL may chose to do Sequential Scans on a table rather than utilize an available index. When table sizes are small, a Seq Scan can be faster. (Note: you can run <code class="highlighter-rouge">SET enable_seqscan = OFF;</code> in a session to get the optimizer to prefer using indexes even when a Sequential Scan may be faster. This is useful when working with development databases that do not have much data in them)</li>
</ul>

<h2 id="understanding-execution-plans">Understanding Execution Plans</h2>

<p>Now that you’ve found some statements that are slow, it’s time for the fun to begin.</p>

<h3 id="explain">EXPLAIN</h3>

<p>The <a href="http://www.postgresql.org/docs/current/static/sql-explain.html">EXPLAIN</a> command is by far the must have when it comes to tuning queries. It tells you what is really going on. To use it, simply prepend your statement with <code class="highlighter-rouge">EXPLAIN</code> and run it. PostgreSQL will show you the execution plan it used.</p>

<p>When using EXPLAIN for tuning, I recommend always using the <code class="highlighter-rouge">ANALYZE</code> option (<code class="highlighter-rouge">EXPLAIN ANALYZE</code>) as it gives you more accurate results. The <code class="highlighter-rouge">ANALYZE</code> option actually executes the statement (rather than just estimating it) and then explains it.</p>

<p>Let’s dive in and start understanding the output of <code class="highlighter-rouge">EXPLAIN</code>. Here’s an example:</p>

<p><amp-img src="/media/pg-execution-plan.png" alt="Postgres Execution Plan Example" width="1766" height="377" layout="responsive"><noscript><img src="/media/pg-execution-plan.png" alt="Postgres Execution Plan Example" width="1766" height="377"></noscript></amp-img></p>

<h3 id="nodes">Nodes</h3>

<p>The first thing to understand is that each indented block with a preceeding “-&gt;” (along with the top line) is called a <em>node</em>. A <em>node</em> is a logical unit of work (a “step” if you will) with an associated cost and execution time. The costs and times presented at each node are cumulative and roll up all child nodes. This means that the very top line (node) shows a cumulative cost and actual time for the entire statement. This is important because you can easily drill down to determine which node(s) are the bottleneck(s).</p>

<h3 id="cost">Cost</h3>

<p><code class="highlighter-rouge">cost=146.63..148.65</code></p>

<p>The first number is start up cost (cost to retrieve first record) and the second number is the cost incurred to process entire node (total cost from start to finish).</p>

<p>The cost is effectively how much work PostgreSQL <em>estimates</em> it will have to do to run the statement. This number is <em>not</em> how much time is required, although there is usually direct correlation to time required for execution. Cost is a combination of 5 work components used to estimate the work required: sequential fetch, non-sequential (random) fetch, processing of row, processing operator (function), and processing index entry. The cost represents I/O and CPU activity and the important thing to know here is that a relatively higher cost means PostgresSQL thinks it will have to do more work. The optimizer makes its decision on which execution plan to use based on the the cost. Lower costs are preferred by the optimizer.</p>

<h3 id="actual-time">Actual time</h3>

<p><code class="highlighter-rouge">actual time=55.009..55.012</code></p>

<p>In milliseconds, the first number is start up time (time to retrieve first record) and the second number is the time taken to process entire node (total time from start to finish). Easy to understand right?</p>

<p>In the example above, it took 55.009ms to get first record and 55.012ms to finish the entire node.</p>

<h3 id="learning-more-about-execution-plans">Learning More about Execution Plans</h3>

<p>There are some really great articles on understanding the output of <code class="highlighter-rouge">EXPLAIN</code> and rather than attempt to rehash them here, I recommend you invest the time to really understand them more by navigating to these 2 great resources:</p>

<ul>
  <li><a href="http://www.depesz.com/2013/04/16/explaining-the-unexplainable/">http://www.depesz.com/2013/04/16/explaining-the-unexplainable/</a></li>
  <li><a href="https://wiki.postgresql.org/images/4/45/Explaining_EXPLAIN.pdf">https://wiki.postgresql.org/images/4/45/Explaining_EXPLAIN.pdf</a></li>
</ul>

<h2 id="query-tuning">Query Tuning</h2>

<p>Now that you know which statements are performing poorly and able see their execution plans, it is time to start tweaking the query to get better performance. This is where you make changes to the queries and/or add indexes to try and get a better execution plan. Start with the bottlenecks and see if there are changes you can make that reduce costs and/or execution times.</p>

<h3 id="a-note-about-data-cache-and-comparing-apples-to-apples">A note about data cache and comparing apples to apples</h3>

<p>As you make changes and evaluate the resuling execution plans to see if it is better, it is important to know that <strong>subsequent executions might be relying upon data caching that yield the perception of better results</strong>. If you run a query once, make a tweak and run it a second time, it is likely it will run much faster even if the execution plan is not more favorable. This is because PostgreSQL might have cached data used in the first run and is able to use it in the second run. Therefore, you should run queries at least 3 times and average the results to compare apples to apples.</p>

<p>Things I’ve learned that <em>may</em> help get better execution plans:</p>

<ul>
  <li>Indexes
    <ul>
      <li>Eliminate Sequential Scans (Seq Scan) by adding indexes (unless table size is small)</li>
      <li>If using a multicolumn index, make sure you pay attention to order in which you define the included columns - <a href="http://use-the-index-luke.com/sql/where-clause/the-equals-operator/concatenated-keys">More info</a>
</li>
      <li>Try to use indexes that are highly selective on commonly-used data. This will make their use more efficient.</li>
    </ul>
  </li>
  <li>WHERE clause
    <ul>
      <li>Avoid LIKE</li>
      <li>Avoid function calls in WHERE clause</li>
      <li>Avoid large IN() statements</li>
    </ul>
  </li>
  <li>JOINs
    <ul>
      <li>When joining tables, try to use a simple equality statement in the ON clause (i.e. <code class="highlighter-rouge">a.id = b.person_id</code>). Doing so allows more efficient join techniques to be used (i.e. Hash Join rather than Nested Loop Join)</li>
      <li>Convert subqueries to JOIN statements when possible as this usually allows the optimizer to understand the intent and possibly chose a better plan</li>
      <li>Use JOINs properly: Are you using GROUP BY or DISTINCT just because you are getting duplicate results? This usually indicates improper JOIN usage and may result in a higher costs</li>
      <li>If the execution plan is using a Hash Join it can be very slow if table size estimates are wrong. Therefore, make sure your table statistics are accurate by reviewing your <a href="http://www.postgresql.org/docs/current/static/routine-vacuuming.html">vacuuming strategy</a>
</li>
      <li>Avoid <a href="https://en.wikipedia.org/wiki/Correlated_subquery">correlated subqueries</a> where possible; they can significantly increase query cost</li>
      <li>Use <a href="http://www.postgresql.org/docs/current/static/functions-subquery.html">EXISTS</a> when checking for existence of rows based on criterion because it “short-circuits” (stops processing when it finds at least one match)</li>
    </ul>
  </li>
  <li>
    <p>General guidelines</p>

    <ul>
      <li>Do more with less; CPU is faster than I/O</li>
      <li>Utilize <a href="http://www.postgresql.org/docs/current/static/queries-with.html">Common Table Expressions</a> and temporary tables when you need to run chained queries</li>
      <li>Avoid LOOP statements and prefer SET operations</li>
      <li>Avoid COUNT(*) as PostgresSQL does table scans for this (<a href="https://wiki.postgresql.org/wiki/FAQ#Why_is_.22SELECT_count.28.2A.29_FROM_bigtable.3B.22_slow.3F">versions &lt;= 9.1 only</a>)</li>
      <li>Avoid ORDER BY, DISTINCT, GROUP BY, UNION when possible because these cause high startup costs</li>
      <li>Look for a large variance between estimated rows and actual rows in the <code class="highlighter-rouge">EXPLAIN</code> statement. If the count is very different, the table statistics could be outdated and PostgreSQL is estimating cost using inaccurate statistics. For example: <code class="highlighter-rouge">Limit (cost=282.37..302.01 rows=93 width=22) (actual time=34.35..49.59 rows=2203 loops=1)</code>. The estimated row count was 93 and the actual was 2,203. Therefore, it is likely making a bad plan decision. You should review your <a href="http://www.postgresql.org/docs/current/static/routine-vacuuming.html">vacuuming strategy</a> and ensure <code class="highlighter-rouge">ANALYZE</code> is being run frequently enough.</li>
    </ul>
  </li>
</ul>

    </div>
    
    <footer class="site-footer">
    © 2019 Brady Holt
</footer>

    <amp-analytics type="googleanalytics">
        <script type="application/json">
        {
            "vars": {
            "account": "UA-19416043-2"
            },
            "triggers": {
            "trackPageview": {
                "on": "visible",
                "request": "pageview"
            }
            }
        }
        </script>
    </amp-analytics>
</body>

</html>